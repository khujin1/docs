{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to FlashBase Docs \u00b6 (TBD) \uc774 \uc0ac\uc774\ud2b8\ub294 MKDocs \ub97c \uc774\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4.","title":"Introduction"},{"location":"#welcome-to-flashbase-docs","text":"(TBD) \uc774 \uc0ac\uc774\ud2b8\ub294 MKDocs \ub97c \uc774\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4.","title":"Welcome to FlashBase Docs"},{"location":"command-line-interface/","text":"Command Line Interface \u00b6 Command Line Interface(CLI) of FlashBase supports not only deploy and start command but also many commands to access and manipulat data in FlashBase. \u200b 1. cluster start \u00b6 Procedure \u00b6 (1) Backup logs of the previous master/slave nodes All log files of previous master/slave nodes in '${SR2_HOME} 1 /logs/redis/' will be moved to '${SR2_HOME}/logs/redis/backup/'. (2) Generate directories to save data Save aof and rdb files of redis-server and RocksDB files in '${SR2_REDIS_DATA}' (3) Start redis-server process Start master and slave redis-server with '${SR2_HOME}/conf/redis/redis-{port}.conf' file Log files will be saved in '${SR2_HOME}/logs/redis/' Error Handling \u00b6 (1) ErrorCode 11 Redis-server(master) process with same port is already running. To resolve this error, use 'cluster stop' or 'kill {pid of the process}'. $ cluster start ... ... [ErrorCode 11] Fail to start... Must be checked running MASTER redis processes! We estimate that redis process is <alive-redis-count>. (2) ErrorCode 12 Redis-server(slave) process with same port is already running. To resolve this error, use 'cluster stop' or 'kill {pid of the process}'. $ cluster start ... [ErrorCode 12] Fail to start... Must be checked running SLAVE redis processes! We estimate that redis process is <alive-redis-count>. (3) Conf file not exist Conf file is not found. To resove this error, use 'cluster configure' and then 'cluster start'. cluster configure \uba85\ub839\uc5b4\ub97c \uc2e4\ud589\uc2dc\ud0a8 \ud6c4 cluster start\ub97c \uc9c4\ud589\ud558\uc138\uc694. $ cluster start ... FileNotExistError: ${SR2_HOME}/conf/redis/redis-{port}.conf (4) max try error \u200b For detail information, please check log files. $ cluster start ... max try error 2. cluster stop \u00b6 \u200bGracefully kill all redis-servers(master/slave) with SIGINT \u200b\u200b Options \u00b6 (1) Force to kill all redis-servers(master/slave) with SIGKILL --force 3. cluster create \u00b6 To-Do \u200b\u200b 4. cluster clean \u00b6 Procedure\u200b \u00b6 (1) Remove conf files for redis-server (2) Remove all data(aof, rdb, RocksDB) of FlashBase 5. cluster restart\u200b \u00b6 Process 'cluster stop' and then 'cluster start'. \u200b\u200b \u200b Options \u00b6 (1) Force to kill all redis-servers(master/slave) with SIGKILL and then start again. --force-stop (2) Remove all data(aof, rdb, RocksDB, conf files) before start again. --reset (3) Process 'cluster create'. This command should be called with '--reset'. --cluster \u200b \u200b If user types 'cfc 1', ${SR2_HOME} will be '~/tsr2/cluster_1/tsr2-assembly-1.0.0-SNAPSHOT'. \u21a9","title":"Command Line Interface"},{"location":"command-line-interface/#command-line-interface","text":"Command Line Interface(CLI) of FlashBase supports not only deploy and start command but also many commands to access and manipulat data in FlashBase. \u200b","title":"Command Line Interface"},{"location":"command-line-interface/#1-cluster-start","text":"","title":"1. cluster start"},{"location":"command-line-interface/#procedure","text":"(1) Backup logs of the previous master/slave nodes All log files of previous master/slave nodes in '${SR2_HOME} 1 /logs/redis/' will be moved to '${SR2_HOME}/logs/redis/backup/'. (2) Generate directories to save data Save aof and rdb files of redis-server and RocksDB files in '${SR2_REDIS_DATA}' (3) Start redis-server process Start master and slave redis-server with '${SR2_HOME}/conf/redis/redis-{port}.conf' file Log files will be saved in '${SR2_HOME}/logs/redis/'","title":"Procedure"},{"location":"command-line-interface/#error-handling","text":"(1) ErrorCode 11 Redis-server(master) process with same port is already running. To resolve this error, use 'cluster stop' or 'kill {pid of the process}'. $ cluster start ... ... [ErrorCode 11] Fail to start... Must be checked running MASTER redis processes! We estimate that redis process is <alive-redis-count>. (2) ErrorCode 12 Redis-server(slave) process with same port is already running. To resolve this error, use 'cluster stop' or 'kill {pid of the process}'. $ cluster start ... [ErrorCode 12] Fail to start... Must be checked running SLAVE redis processes! We estimate that redis process is <alive-redis-count>. (3) Conf file not exist Conf file is not found. To resove this error, use 'cluster configure' and then 'cluster start'. cluster configure \uba85\ub839\uc5b4\ub97c \uc2e4\ud589\uc2dc\ud0a8 \ud6c4 cluster start\ub97c \uc9c4\ud589\ud558\uc138\uc694. $ cluster start ... FileNotExistError: ${SR2_HOME}/conf/redis/redis-{port}.conf (4) max try error \u200b For detail information, please check log files. $ cluster start ... max try error","title":"Error Handling"},{"location":"command-line-interface/#2-cluster-stop","text":"\u200bGracefully kill all redis-servers(master/slave) with SIGINT \u200b\u200b","title":"2. cluster stop"},{"location":"command-line-interface/#options","text":"(1) Force to kill all redis-servers(master/slave) with SIGKILL --force","title":"Options"},{"location":"command-line-interface/#3-cluster-create","text":"To-Do \u200b\u200b","title":"3. cluster create"},{"location":"command-line-interface/#4-cluster-clean","text":"","title":"4. cluster clean"},{"location":"command-line-interface/#procedure_1","text":"(1) Remove conf files for redis-server (2) Remove all data(aof, rdb, RocksDB) of FlashBase","title":"Procedure\u200b"},{"location":"command-line-interface/#5-cluster-restart","text":"Process 'cluster stop' and then 'cluster start'. \u200b\u200b \u200b","title":"5. cluster restart\u200b"},{"location":"command-line-interface/#options_1","text":"(1) Force to kill all redis-servers(master/slave) with SIGKILL and then start again. --force-stop (2) Remove all data(aof, rdb, RocksDB, conf files) before start again. --reset (3) Process 'cluster create'. This command should be called with '--reset'. --cluster \u200b \u200b If user types 'cfc 1', ${SR2_HOME} will be '~/tsr2/cluster_1/tsr2-assembly-1.0.0-SNAPSHOT'. \u21a9","title":"Options"},{"location":"get-started/","text":"Get Started with FlashBase \u00b6 In ./scripts , you can find all files that are used in this document . -rw-r--r-- 1 admin SDomain Users 701B 11 5 10:07 .use_cluster -rw-r--r--@ 1 admin Domain Users 488B 11 5 10:08 ddl_fb_test_101.sql -rwxr-xr-x@ 1 admin Domain Users 1.7K 11 5 10:07 deploy-flashbase.sh -rw-r--r--@ 1 admin Domain Users 155B 11 5 10:08 test.json -rw-r--r--@ 1 admin Domain Users 17K 11 5 10:08 test_data.csv 1. Optimizing System Parameters \u00b6 System Parameters \u00b6 (1) Edit /etc/sysctl.conf like following ... vm.swappiness = 0 vm.overcommit_memory = 1 vm.overcommit_ratio = 50 fs.file-max = 6815744 net.ipv4.ip_local_port_range = 32768 65535 net.core.rmem_default = 262144 net.core.wmem_default = 262144 net.core.rmem_max = 16777216 net.core.wmem_max = 16777216 net.ipv4.tcp_max_syn_backlog = 4096 net.core.somaxconn = 65535 ... Tip In case of application in runtime, use sudo sysctl -p (2) Edit /etc/security/limits.conf ... * soft nofile 262144 * hard nofile 262144 * soft nproc 131072 * hard nproc 131072 [account name] * soft nofile 262144 [account name] * hard nofile 262144 [account name] * soft nproc 131072 [account name] * hard nproc 131072 ... Tip In case of application in runtime, use ulimit -n 65535, ulimit -u 131072 (3) Edit /etc/fstab Remove SWAP Partition (Comment out SWAP partition with using # and reboot) ... #/dev/mapper/centos-swap swap swap defaults 0 0 ... Tip In case of application in runtime, use swapoff -a (4) /etc/init.d/disable-transparent-hugepages root@fbg01 ~] cat /etc/init.d/disable-transparent-hugepages #!/bin/bash ### BEGIN INIT INFO # Provides: disable-transparent-hugepages # Required-Start: $local_fs # Required-Stop: # X-Start-Before: mongod mongodb-mms-automation-agent # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Disable Linux transparent huge pages # Description: Disable Linux transparent huge pages, to improve # database performance. ### END INIT INFO case $1 in start) if [ -d /sys/kernel/mm/transparent_hugepage ]; then thp_path=/sys/kernel/mm/transparent_hugepage elif [ -d /sys/kernel/mm/redhat_transparent_hugepage ]; then thp_path=/sys/kernel/mm/redhat_transparent_hugepage else return 0 fi echo 'never' > ${thp_path}/enabled echo 'never' > ${thp_path}/defrag re='^[0-1]+$' if [[ $(cat ${thp_path}/khugepaged/defrag) =~ $re ]] then # RHEL 7 echo 0 > ${thp_path}/khugepaged/defrag else # RHEL 6 echo 'no' > ${thp_path}/khugepaged/defrag fi unset re unset thp_path ;; esac [root@fbg01 ~] [root@fbg01 ~] [root@fbg01 ~] chmod 755 /etc/init.d/disable-transparent-hugepages [root@fbg01 ~] chkconfig --add disable-transparent-hugepages 2. Setup Prerequisites \u00b6 Install Packages \u00b6 bash, unzip, ssh JDK 1.8 or higher gcc 4.8.5 or higher glibc 2.17 or higher epel-release sudo yum install epel-release boost, boost-thread, boost-devel sudo yum install boost boost-thread boost-devel Exchange SSH Key For all servers that FlashBase will be deployed, SSH key should be exchanged. ssh-keygen -t rsa chmod 0600 ~/.ssh/authorized_keys cat .ssh/id_rsa.pub | ssh {server name} \"cat >> .ssh/authorized_keys\" Intel MKL library (1) Intel MKL 2019 library install go to the website: https://software.intel.com/en-us/mkl/choose-download/macos register and login select product named \"Intel * Math Kernel Library for Linux\" or \"Intel * Math Kernel Library for Mac\" from the select box \"Choose Product to Download\" Choose a Version \"2019 Update 2\" and download unzip the file and execute the install.sh file with root account or (sudo command) sudo ./install.sh choose custom install and configure the install directory /opt/intel (with sudo, /opt/intel is the default installation path, just confirm it) matthew@fbg05 /opt/intel $ pwd /opt/intel matthew@fbg05 /opt/intel $ ls -alh \ud569\uacc4 0 drwxr-xr-x 10 root root 307 3\uc6d4 22 01:34 . drwxr-xr-x. 5 root root 83 3\uc6d4 22 01:34 .. drwxr-xr-x 6 root root 72 3\uc6d4 22 01:35 .pset drwxr-xr-x 2 root root 53 3\uc6d4 22 01:34 bin lrwxrwxrwx 1 root root 28 3\uc6d4 22 01:34 compilers_and_libraries -> compilers_and_libraries_2019 drwxr-xr-x 3 root root 19 3\uc6d4 22 01:34 compilers_and_libraries_2019 drwxr-xr-x 4 root root 36 1\uc6d4 24 23:04 compilers_and_libraries_2019.2.187 drwxr-xr-x 6 root root 63 1\uc6d4 24 22:50 conda_channel drwxr-xr-x 4 root root 26 1\uc6d4 24 23:01 documentation_2019 lrwxrwxrwx 1 root root 33 3\uc6d4 22 01:34 lib -> compilers_and_libraries/linux/lib lrwxrwxrwx 1 root root 33 3\uc6d4 22 01:34 mkl -> compilers_and_libraries/linux/mkl lrwxrwxrwx 1 root root 29 3\uc6d4 22 01:34 parallel_studio_xe_2019 -> parallel_studio_xe_2019.2.057 drwxr-xr-x 5 root root 216 3\uc6d4 22 01:34 parallel_studio_xe_2019.2.057 drwxr-xr-x 3 root root 16 3\uc6d4 22 01:34 samples_2019 lrwxrwxrwx 1 root root 33 3\uc6d4 22 01:34 tbb -> compilers_and_libraries/linux/tbb (2) Intel MKL 2019 library environment settings append the following statement into ~/.bashrc # INTEL MKL enviroment variables for ($MKLROOT, can be checked with the value export | grep MKL) source /opt/intel/mkl/bin/mklvars.sh intel64 Apache Hadoop 2.6.0 (or higher) Apache Spark 2.3 on Hadoop 2.6 ntp: For clock synchronization between servers over packet-switched, variable-latency data networks. 3. Session configuration files \u00b6 Edit ~/.bashrc Add followings # .bashrc if [ -f /etc/bashrc ]; then . /etc/bashrc fi # User specific environment and startup programs PATH=$PATH:$HOME/.local/bin:$HOME/bin HADOOP_HOME=/home/nvkvs/hadoop HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop SPARK_HOME=/home/nvkvs/spark PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$HOME/sbin export PATH SPARK_HOME HADOOP_HOME HADOOP_CONF_DIR YARN_CONF_DIR alias cfc='source ~/.use_cluster' Add ~/.use_cluster This script helps to change the path of FlasBase Cluster. #!/bin/bash ## set cluster-#{NUM} path export PATH=\"/bin/:/sbin/:/usr/local/bin/:/usr/local/sbin\" export SR2_HOME=${HOME}/tsr2/cluster_$1/tsr2-assembly-1.0.0-SNAPSHOT source ${HOME}/.bash_profile echo $PATH | grep ${SR2_HOME} > /dev/null RET=$? if [[ $RET -eq 1 ]]; then PATH=$PATH:$SR2_HOME/bin:$SR2_HOME/sbin fi ## source command auto-complate source $SR2_HOME/sbin/tsr2-helper if [ \"$#\" -le \"1\" ]; then return 0 else shift \"$@\" return $? fi 4. Install and Start FlashBase \u00b6 Use Command Line Interface of FlashBase.","title":"Get Started"},{"location":"get-started/#get-started-with-flashbase","text":"In ./scripts , you can find all files that are used in this document . -rw-r--r-- 1 admin SDomain Users 701B 11 5 10:07 .use_cluster -rw-r--r--@ 1 admin Domain Users 488B 11 5 10:08 ddl_fb_test_101.sql -rwxr-xr-x@ 1 admin Domain Users 1.7K 11 5 10:07 deploy-flashbase.sh -rw-r--r--@ 1 admin Domain Users 155B 11 5 10:08 test.json -rw-r--r--@ 1 admin Domain Users 17K 11 5 10:08 test_data.csv","title":"Get Started with FlashBase"},{"location":"get-started/#1-optimizing-system-parameters","text":"","title":"1. Optimizing System Parameters"},{"location":"get-started/#system-parameters","text":"(1) Edit /etc/sysctl.conf like following ... vm.swappiness = 0 vm.overcommit_memory = 1 vm.overcommit_ratio = 50 fs.file-max = 6815744 net.ipv4.ip_local_port_range = 32768 65535 net.core.rmem_default = 262144 net.core.wmem_default = 262144 net.core.rmem_max = 16777216 net.core.wmem_max = 16777216 net.ipv4.tcp_max_syn_backlog = 4096 net.core.somaxconn = 65535 ... Tip In case of application in runtime, use sudo sysctl -p (2) Edit /etc/security/limits.conf ... * soft nofile 262144 * hard nofile 262144 * soft nproc 131072 * hard nproc 131072 [account name] * soft nofile 262144 [account name] * hard nofile 262144 [account name] * soft nproc 131072 [account name] * hard nproc 131072 ... Tip In case of application in runtime, use ulimit -n 65535, ulimit -u 131072 (3) Edit /etc/fstab Remove SWAP Partition (Comment out SWAP partition with using # and reboot) ... #/dev/mapper/centos-swap swap swap defaults 0 0 ... Tip In case of application in runtime, use swapoff -a (4) /etc/init.d/disable-transparent-hugepages root@fbg01 ~] cat /etc/init.d/disable-transparent-hugepages #!/bin/bash ### BEGIN INIT INFO # Provides: disable-transparent-hugepages # Required-Start: $local_fs # Required-Stop: # X-Start-Before: mongod mongodb-mms-automation-agent # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: Disable Linux transparent huge pages # Description: Disable Linux transparent huge pages, to improve # database performance. ### END INIT INFO case $1 in start) if [ -d /sys/kernel/mm/transparent_hugepage ]; then thp_path=/sys/kernel/mm/transparent_hugepage elif [ -d /sys/kernel/mm/redhat_transparent_hugepage ]; then thp_path=/sys/kernel/mm/redhat_transparent_hugepage else return 0 fi echo 'never' > ${thp_path}/enabled echo 'never' > ${thp_path}/defrag re='^[0-1]+$' if [[ $(cat ${thp_path}/khugepaged/defrag) =~ $re ]] then # RHEL 7 echo 0 > ${thp_path}/khugepaged/defrag else # RHEL 6 echo 'no' > ${thp_path}/khugepaged/defrag fi unset re unset thp_path ;; esac [root@fbg01 ~] [root@fbg01 ~] [root@fbg01 ~] chmod 755 /etc/init.d/disable-transparent-hugepages [root@fbg01 ~] chkconfig --add disable-transparent-hugepages","title":"System Parameters"},{"location":"get-started/#2-setup-prerequisites","text":"","title":"2. Setup Prerequisites"},{"location":"get-started/#install-packages","text":"bash, unzip, ssh JDK 1.8 or higher gcc 4.8.5 or higher glibc 2.17 or higher epel-release sudo yum install epel-release boost, boost-thread, boost-devel sudo yum install boost boost-thread boost-devel Exchange SSH Key For all servers that FlashBase will be deployed, SSH key should be exchanged. ssh-keygen -t rsa chmod 0600 ~/.ssh/authorized_keys cat .ssh/id_rsa.pub | ssh {server name} \"cat >> .ssh/authorized_keys\" Intel MKL library (1) Intel MKL 2019 library install go to the website: https://software.intel.com/en-us/mkl/choose-download/macos register and login select product named \"Intel * Math Kernel Library for Linux\" or \"Intel * Math Kernel Library for Mac\" from the select box \"Choose Product to Download\" Choose a Version \"2019 Update 2\" and download unzip the file and execute the install.sh file with root account or (sudo command) sudo ./install.sh choose custom install and configure the install directory /opt/intel (with sudo, /opt/intel is the default installation path, just confirm it) matthew@fbg05 /opt/intel $ pwd /opt/intel matthew@fbg05 /opt/intel $ ls -alh \ud569\uacc4 0 drwxr-xr-x 10 root root 307 3\uc6d4 22 01:34 . drwxr-xr-x. 5 root root 83 3\uc6d4 22 01:34 .. drwxr-xr-x 6 root root 72 3\uc6d4 22 01:35 .pset drwxr-xr-x 2 root root 53 3\uc6d4 22 01:34 bin lrwxrwxrwx 1 root root 28 3\uc6d4 22 01:34 compilers_and_libraries -> compilers_and_libraries_2019 drwxr-xr-x 3 root root 19 3\uc6d4 22 01:34 compilers_and_libraries_2019 drwxr-xr-x 4 root root 36 1\uc6d4 24 23:04 compilers_and_libraries_2019.2.187 drwxr-xr-x 6 root root 63 1\uc6d4 24 22:50 conda_channel drwxr-xr-x 4 root root 26 1\uc6d4 24 23:01 documentation_2019 lrwxrwxrwx 1 root root 33 3\uc6d4 22 01:34 lib -> compilers_and_libraries/linux/lib lrwxrwxrwx 1 root root 33 3\uc6d4 22 01:34 mkl -> compilers_and_libraries/linux/mkl lrwxrwxrwx 1 root root 29 3\uc6d4 22 01:34 parallel_studio_xe_2019 -> parallel_studio_xe_2019.2.057 drwxr-xr-x 5 root root 216 3\uc6d4 22 01:34 parallel_studio_xe_2019.2.057 drwxr-xr-x 3 root root 16 3\uc6d4 22 01:34 samples_2019 lrwxrwxrwx 1 root root 33 3\uc6d4 22 01:34 tbb -> compilers_and_libraries/linux/tbb (2) Intel MKL 2019 library environment settings append the following statement into ~/.bashrc # INTEL MKL enviroment variables for ($MKLROOT, can be checked with the value export | grep MKL) source /opt/intel/mkl/bin/mklvars.sh intel64 Apache Hadoop 2.6.0 (or higher) Apache Spark 2.3 on Hadoop 2.6 ntp: For clock synchronization between servers over packet-switched, variable-latency data networks.","title":"Install Packages"},{"location":"get-started/#3-session-configuration-files","text":"Edit ~/.bashrc Add followings # .bashrc if [ -f /etc/bashrc ]; then . /etc/bashrc fi # User specific environment and startup programs PATH=$PATH:$HOME/.local/bin:$HOME/bin HADOOP_HOME=/home/nvkvs/hadoop HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop SPARK_HOME=/home/nvkvs/spark PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$HOME/sbin export PATH SPARK_HOME HADOOP_HOME HADOOP_CONF_DIR YARN_CONF_DIR alias cfc='source ~/.use_cluster' Add ~/.use_cluster This script helps to change the path of FlasBase Cluster. #!/bin/bash ## set cluster-#{NUM} path export PATH=\"/bin/:/sbin/:/usr/local/bin/:/usr/local/sbin\" export SR2_HOME=${HOME}/tsr2/cluster_$1/tsr2-assembly-1.0.0-SNAPSHOT source ${HOME}/.bash_profile echo $PATH | grep ${SR2_HOME} > /dev/null RET=$? if [[ $RET -eq 1 ]]; then PATH=$PATH:$SR2_HOME/bin:$SR2_HOME/sbin fi ## source command auto-complate source $SR2_HOME/sbin/tsr2-helper if [ \"$#\" -le \"1\" ]; then return 0 else shift \"$@\" return $? fi","title":"3. Session configuration files"},{"location":"get-started/#4-install-and-start-flashbase","text":"Use Command Line Interface of FlashBase.","title":"4. Install and Start FlashBase"}]}